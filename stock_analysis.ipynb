{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "manual-brother",
   "metadata": {},
   "source": [
    "### RNN Model for Stock Analysis\n",
    "\n",
    "1. import data from csv datsets\n",
    "    - prices\n",
    "    - sector and industry \n",
    "    - revenue\n",
    "    - profit\n",
    "2. compile into timestep sequence\n",
    "3. create lagged y-value set\n",
    "4. create model\n",
    "    - lstm cell\n",
    "    - dense layer\n",
    "    - consider another lstm and dense layer\n",
    "    - output\n",
    "5. run model based on following inputs for each time step\n",
    "    - market cap\n",
    "    - industry (one-hot vector)\n",
    "    - sector (one-hot vector)\n",
    "    - revenue\n",
    "    - profit\n",
    "6. predict\n",
    "    - run model up until the known value is done\n",
    "    - iterate through following values feeding previous output and hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-divide",
   "metadata": {},
   "source": [
    "#### Initialize definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "small-delivery",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# using tensorflow.keras may be necessary, keras by itself may not work\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply, TimeDistributed, Reshape, Dropout\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsolutePercentageError\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "present-position",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define constants and filepaths\n",
    "\n",
    "shareprices_path = 'raw/us-shareprices-daily.csv'\n",
    "income_path = 'raw/us-income-ttm.csv'\n",
    "# shareprices_path = 'us-shareprices-latest.csv' # latest data only, helps shorten load time while developing\n",
    "\n",
    "MAX_DAYS = 9000 # number of total days possible for a stock\n",
    "T_x = 1 # number of timesteps inputs\n",
    "T_y = 1 # number of timestep outputs, T_x = T_y or 1, depending on the architecture\n",
    "# n_a1 = 256 # number of hidden activation units in first LSTM layer\n",
    "# n_a2 = 256 # number of hidden activation units in second LSTM layer\n",
    "n_inputs = 5 # number of input variables per timestep\n",
    "n_values = n_inputs # number of output predicted variables, may be same as n_inputs\n",
    "n_trailing = T_x # number of trailing days used for prediction\n",
    "n_forward = 2000 # number of timesteps in advance for forward prediction\n",
    "m = 150000 # number of training examples\n",
    "\n",
    "sc = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-eating",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "\n",
    "1. Import all datasets using pandas\n",
    "2. Add market cap, revenue, profit, and yoy growth by quarter to dataset\n",
    "    - Make data repeat until following quarter\n",
    "3. Create a second dataset with sector of the company\n",
    "4. Slice dataset into arrays of length T_x+1 and pair with sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "unauthorized-artist",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, cols=None, delimiter=';'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Loads a dataset from csv file into pandas dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    path -- filepath to csv\n",
    "    cols -- column labels to pass into reader, first label should be the date column label\n",
    "    delimiter -- delimiter of values, default semicolon based on project data\n",
    "    \n",
    "    Returns:\n",
    "    df -- dataframe with values from csv\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(path, delimiter=delimiter, usecols=cols)\n",
    "    df.index = pd.to_datetime(df.pop(cols[0])) # alternatively, df.index = pd.to_datetime(df[cols[0]]); df = df.drop(columns=[cols[0]])\n",
    "    df.index.name = 'Date' # renames column if date column originally has different name\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "purple-chapel",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data(df, na=False, zeros=None, min_freq=1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Removes rows with incomplete data, either NaN or zero values, based on specified columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df -- input dataframe\n",
    "    na -- labels of columns to consider when removing rows with NaN values, default of False removes no rows (False instead of None because None removes all rows)\n",
    "    zeros -- label of columns considered when removing rows with zero values, default of None removes no rows\n",
    "    min_freq -- minimum number of rows of a ticker to remain in dataset, default of 1 removes no rows\n",
    "    \n",
    "    Returns:\n",
    "    df -- dataframe with data cleaned\n",
    "    \"\"\"\n",
    "    \n",
    "    if na == 'all': na = df.columns[df.dtypes!='object'] # sets to columns with non-string dtypes\n",
    "    if zeros == 'all': zeros = df.columns[df.dtypes!='object']\n",
    "    \n",
    "    if not na is False: df = df.dropna(subset=na) # removes all rows with NaN in specified columns, df.dropna(subset=[na], inplace=True) also works if SettingWithCopyWarning appears\n",
    "    if not zeros is None: df = df[(df[zeros]!=0).all(axis=1)] # removes all rows with zero values in specified columns, see https://stackoverflow.com/a/22650162/6501621 and https://stackoverflow.com/questions/18172851/deleting-dataframe-row-in-pandas-based-on-column-value\n",
    "    df = df[df.groupby('Ticker')['Ticker'].transform(len) >= min_freq] # removes all rows of a stock if stock has less than min_freq entries, see https://stackoverflow.com/a/48514338/6501621\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "confidential-climb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_derived_value(df, method, base_cols, deriv_cols, drop=False, group=None, periods=4):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes derived value based on method and parameters. Available derived values: percent change, multiplication.\n",
    "    \n",
    "    Parameters:\n",
    "    df -- input dataframe (required)\n",
    "    method -- computation to calculate derived values (required)\n",
    "    base_cols -- list of column labels of base values used to compute derived values (required)\n",
    "    deriv_cols -- list of column label(s) of derived values to add to dataframe (required)\n",
    "    drop -- column label(s) to drop after computation (optional)\n",
    "    group -- column label of grouping if necessary for calculation (optional)\n",
    "    period -- number of periods between percent change calculation (optional)\n",
    "    \n",
    "    Returns:\n",
    "    df -- dataframe with additional column(s) of derived calculations\n",
    "    \"\"\"\n",
    "    \n",
    "    # computes percentage change of base columns and adds to dataframe in new columns\n",
    "    \n",
    "    if method == 'pctchg':\n",
    "        growth = lambda x: x.pct_change(periods=periods).backfill() # defines function to compute percent change and backfills missing data\n",
    "        for base_col, deriv_col in zip(base_cols, deriv_cols): # loops through if applicable to multiple columns\n",
    "            growth_col = df.groupby(group)[base_col].apply(growth) # applies function by group\n",
    "            df[deriv_col] = growth_col # assigns derived values to specified column name\n",
    "        \n",
    "    # multiplies base columns together to create a new column\n",
    "    \n",
    "    elif method == 'multiply':\n",
    "        multiply = df[base_cols[0]] # initializes variable\n",
    "        for col in base_cols[1:]: multiply *= df[col] # loops through all other columns to multiply together into variable\n",
    "        df[deriv_cols] = multiply # assigns derived values to specified column name, only one column can be specified in deriv_cols\n",
    "        \n",
    "    if drop: df = df.drop(columns=base_cols) # delete base columns after calculating derived values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "starting-values",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def access_ticker(df, ticker):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the rows of a given ticker.\n",
    "    \n",
    "    Parameters:\n",
    "    df -- input dataframe\n",
    "    ticker -- stock ticker to retrieve values of\n",
    "    \n",
    "    Returns:\n",
    "    df -- dataframe of rows of selected ticker\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(df.index.names) <= 1: # access from single index\n",
    "        return df[df['Ticker']==ticker]\n",
    "    else: # access from MultiIndex\n",
    "        return df.loc[ticker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "growing-powder",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rescale_data_by_group(df, group, freq='1D'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Rescales data from original frequency to specified frequency and forward fills empty rows if upscaling.\n",
    "    \n",
    "    Parameters:\n",
    "    df -- input dataframe to rescale\n",
    "    group -- column of grouping\n",
    "    frequency -- frequency of data for each group\n",
    "    \"\"\"\n",
    "    \n",
    "    rescale = lambda x: x.asfreq(freq).pad() # defines function to rescale data to specified frequency\n",
    "    df = df.groupby(group).apply(rescale) # applies function by group\n",
    "    df.pop(group) # df.drop provides same functionality for this use case\n",
    "    df = df.reset_index(level=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "potential-passenger",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_sequences(data, n_trailing=n_trailing, n_forward=n_forward):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates all sequences of input array given number of timesteps and length of forward projection.\n",
    "    \n",
    "    Parameters:\n",
    "    data -- input array\n",
    "    n_trailing -- number of timesteps used in sequence\n",
    "    n_forward -- projection number of days in advance\n",
    "    \n",
    "    Return:\n",
    "    sequences -- list of sequences generated from array\n",
    "    \"\"\"\n",
    "    \n",
    "    sequences = []\n",
    "    \n",
    "    for i in range(len(data)-n_trailing-n_forward+1):\n",
    "        sequences.append(np.append(data[i:i+n_trailing], [data[i+n_trailing+n_forward-1]], axis=0)) # appends the n_trailing timesteps and timestep n_forward from most recent timestep\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "taken-failing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def notify(title, text=\"\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Displays a desktop notification with specified text.\n",
    "    \n",
    "    Parameters:\n",
    "    title -- title of notification to be displayed\n",
    "    text -- further details of notification\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    os.system(\"\"\"\n",
    "              osascript -e 'display notification \"{}\" with title \"{}\"'\n",
    "              \"\"\".format(text, title))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-occasion",
   "metadata": {},
   "source": [
    "#### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "intended-advocacy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_loss_function(loss, weights):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes a loss function with weighting on specific outputs.\n",
    "    Based on https://keras.io/api/losses/\n",
    "    https://towardsdatascience.com/how-to-create-a-custom-loss-function-keras-3a89156ec69b\n",
    "    https://medium.com/@Bloomore/how-to-write-a-custom-loss-function-with-additional-arguments-in-keras-5f193929f7a0\n",
    "    \n",
    "    Parameters:\n",
    "    loss -- loss options (mean squared error, mean absolute percentage error)\n",
    "    weights -- list of loss weighting of output ['Market Cap', 'Revenue', 'Gross Profit', 'Net Income', 'YoY Revenue']\n",
    "    \n",
    "    Returns:\n",
    "    custom_loss -- defines a custom error with loss weighting\n",
    "    \"\"\"\n",
    "    \n",
    "    loss_weights = K.constant(np.array([weights]))\n",
    "    num_weights = np.sum(np.ones(len(weights))) # workaround because it seems multiplying by len(weights) directly doesn't work\n",
    "    \n",
    "    if loss == 'mse':\n",
    "        def custom_loss(y_true, y_pred):\n",
    "            loss = K.square(y_true - y_pred) # square before weighting losses, otherwise it gets messy\n",
    "            weighted_loss = Multiply()([loss, loss_weights]) / np.sum(loss_weights) * num_weights # multiply by weights / sum of weights * num weights intuitively makes sense; the sum of (weights / sum of weights) = 1, so to recalibrate based on  original neutral weighting, multiply by length of weights (recalibration is unnecessary but nice)\n",
    "            return K.mean(weighted_loss)\n",
    "        \n",
    "    elif loss == 'mape':\n",
    "        def custom_loss(y_true, y_pred):\n",
    "            diff = y_true - y_pred\n",
    "            loss = 100 * K.abs(diff / y_true) # abs includes y_true because y_true may have negative values\n",
    "            weighted_loss = Multiply()([loss, loss_weights]) / np.sum(loss_weights) * num_weights\n",
    "            return K.mean(weighted_loss)\n",
    "    \n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-geology",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "sunrise-characterization",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize income dataset\n",
    "\n",
    "cols = ['Publish Date', 'Ticker', 'Revenue', 'Gross Profit', 'Net Income']\n",
    "df_income = load_dataset(path=income_path, cols=cols)\n",
    "df_income = clean_data(df_income, na='all', zeros='all', min_freq=5) # df_income.dtypes!='object'] is essentially everything except strings, don't forget it is '!=', not '=='\n",
    "df_income = add_derived_value(df=df_income, method='pctchg', group='Ticker', base_cols=['Revenue'], deriv_cols=['YoY Revenue'], periods=4) # add YoY revenue column by calculating percent change\n",
    "df_income = rescale_data_by_group(df_income, group='Ticker', freq='1D') # somehow turns 'Net Income' from int64 to float64?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "introductory-country",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize prices dataset\n",
    "\n",
    "cols = ['Date', 'Ticker', 'Close', 'Shares Outstanding']\n",
    "df_prices = load_dataset(path=shareprices_path, cols=cols)\n",
    "df_prices = clean_data(df_prices, na='all', zeros='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "amazing-scroll",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute marketcap and remove other variables\n",
    "\n",
    "df_prices = add_derived_value(df=df_prices, method='multiply', base_cols=['Close', 'Shares Outstanding'], deriv_cols=['Market Cap'], group='Ticker', drop=True)\n",
    "df_prices = df_prices[df_prices['Market Cap'] > 1e9] # only companies of value $1B or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "lovely-quarter",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge income and prices\n",
    "\n",
    "df_main = df_prices.merge(df_income, on=['Ticker', 'Date'], how='inner') # inner means stock must be included in both pre-merge; if MultiIndex, the on=[] parameter determines order of pivot table\n",
    "# assert not np.any(np.isnan(df_main))\n",
    "assert not df_main.isna().any(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "incredible-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = clean_data(df_main, min_freq=n_forward+1) # takes only those that are sizable enough, though if n_forward is under 365, unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "modern-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scale data\n",
    "\n",
    "cols = df_main.columns[df_main.dtypes=='float64'] # ['Market Cap', 'Revenue', 'Gross Profit', 'Net Income']\n",
    "\n",
    "sc = MinMaxScaler(feature_range=(1e-15,1)) # duplicate initialization but useful to define here too, see https://stackoverflow.com/questions/49330195/how-to-use-inverse-transform-in-minmaxscaler-for-a-column-in-a-matrix for more on MinMaxScaler\n",
    "sc = sc.fit(df_main[cols])\n",
    "df_main[cols] = sc.transform(df_main[cols])\n",
    "df_main[cols] = np.log(df_main[cols])\n",
    "# sc2 = MinMaxScaler(feature_range=(0,1)) # not sure if necessary\n",
    "# df_main[cols] = sc2.fit_transform(df_main[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "significant-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to list of numpy arrays\n",
    "\n",
    "df_main = pd.pivot_table(df_main, index=['Ticker', 'Date']).reindex(columns=df_main.columns[1:]) # see https://stackoverflow.com/questions/36346071/pandas-pivot-table-changing-order-of-non-index-columns\n",
    "export = lambda x: x.to_numpy()\n",
    "dataset = df_main.groupby('Ticker').apply(export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "fundamental-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to training data format\n",
    "\n",
    "full_dataset = []\n",
    "for i, stock_data in enumerate(dataset):\n",
    "    full_dataset += [generate_sequences(stock_data)[0]] # see https://www.geeksforgeeks.org/python-ways-to-concatenate-two-lists/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "olive-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to np array\n",
    "\n",
    "full_data = np.asarray(full_dataset)\n",
    "# np.save('saved/dataset', full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "electoral-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from npy file\n",
    "\n",
    "# full_data = np.load('saved/dataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "sharp-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(654, 2, 5)"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "solved-berry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.50746788,  -3.82907086,  -3.1894315 ,  -1.24672777,\n",
       "         -2.7465336 ],\n",
       "       [ -9.23692953,  -3.61018389,  -3.14406559,  -1.24589747,\n",
       "         -2.7462545 ]])"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "protected-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(full_data))\n",
    "random.shuffle(indices)\n",
    "m = 725\n",
    "X = full_data[indices[:m],:-1,:]\n",
    "Y = full_data[indices[:m],-1:,:]\n",
    "# Y = Y.reshape(Y.shape[0], Y.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-chess",
   "metadata": {},
   "source": [
    "#### Model Attempt 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "subject-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model5_v1_1():\n",
    "    \n",
    "    \"\"\"\n",
    "    This model is based on model v5.1 but focuses on a single input (e.g., IPO price, or first datapoint).\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape=(1, n_inputs))\n",
    "    X = Dense(units=128, activation='relu')(X_input)\n",
    "    X = Dense(units=128, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(units=128, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(units=64, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    output = Dense(units=n_values, activation='linear')(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "voluntary-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model5_v1():\n",
    "    \n",
    "    \"\"\"\n",
    "    This model is based on model v4.1 but extends the input to 5 inputs and 5 outputs. Designed with a larger dataset\n",
    "    in mind and additional computation power.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape=(T_x, n_inputs))\n",
    "    X = LSTM(units=128, return_sequences=True)(X_input)\n",
    "    X = TimeDistributed(Dense(units=256))(X)\n",
    "    X = LSTM(units=256, return_sequences=True)(X)\n",
    "    X = TimeDistributed(Dense(units=256))(X)\n",
    "    X = LSTM(units=128)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "    X = Dense(units=128)(X)\n",
    "    output = Dense(units=n_values)(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "entire-begin",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model5():\n",
    "    \n",
    "    \"\"\"\n",
    "    This model is based on model v4.1 but extends the input to 5 inputs and 5 outputs. Designed with a larger dataset\n",
    "    in mind and additional computation power.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape=(T_x, n_inputs))\n",
    "    X = LSTM(units=128, return_sequences=True)(X_input)\n",
    "    X = TimeDistributed(Dense(units=256))(X)\n",
    "    X = LSTM(units=128)(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(units=128)(X)\n",
    "    output = Dense(units=n_values)(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "critical-fiber",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# consider using a data generator, see https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load('data/' + ID + '.npy')\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "applied-bottle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model5_v1_1()\n",
    "model.compile(optimizer='adam', loss=custom_loss_function(loss='mse', weights=[1,0,0,0,0]), metrics=['mape']) # consider loss='msle' (mean squared logarithmic error, https://keras.io/api/losses/regression_losses/#meansquaredlogarithmicerror-class), or log during preprocessing (see https://stats.stackexchange.com/questions/213897/best-way-to-optimize-mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "id": "absent-margin",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 654 samples\n",
      "Epoch 1/100\n",
      "654/654 [==============================] - 1s 2ms/sample - loss: 6.9854 - mape: 140.5033\n",
      "Epoch 2/100\n",
      "654/654 [==============================] - 0s 372us/sample - loss: 2.8310 - mape: 129.1189\n",
      "Epoch 3/100\n",
      "654/654 [==============================] - 0s 373us/sample - loss: 2.3565 - mape: 123.2891\n",
      "Epoch 4/100\n",
      "654/654 [==============================] - 0s 371us/sample - loss: 2.2752 - mape: 117.1025\n",
      "Epoch 5/100\n",
      "654/654 [==============================] - 0s 368us/sample - loss: 2.1696 - mape: 109.1633\n",
      "Epoch 6/100\n",
      "654/654 [==============================] - 0s 365us/sample - loss: 2.1897 - mape: 105.2793\n",
      "Epoch 7/100\n",
      "654/654 [==============================] - 0s 392us/sample - loss: 1.9024 - mape: 107.1816\n",
      "Epoch 8/100\n",
      "654/654 [==============================] - 0s 391us/sample - loss: 2.2069 - mape: 112.1462 - loss: 2.3254 - mape: 113.\n",
      "Epoch 9/100\n",
      "654/654 [==============================] - 0s 380us/sample - loss: 2.0923 - mape: 107.7915\n",
      "Epoch 10/100\n",
      "654/654 [==============================] - 0s 390us/sample - loss: 1.8976 - mape: 108.9321\n",
      "Epoch 11/100\n",
      "654/654 [==============================] - 0s 388us/sample - loss: 1.8434 - mape: 94.8187\n",
      "Epoch 12/100\n",
      "654/654 [==============================] - 0s 368us/sample - loss: 1.7721 - mape: 89.4193\n",
      "Epoch 13/100\n",
      "654/654 [==============================] - 0s 370us/sample - loss: 1.7067 - mape: 95.1046\n",
      "Epoch 14/100\n",
      "654/654 [==============================] - 0s 372us/sample - loss: 1.9142 - mape: 86.7051\n",
      "Epoch 15/100\n",
      "654/654 [==============================] - 0s 368us/sample - loss: 1.8241 - mape: 91.3171\n",
      "Epoch 16/100\n",
      "654/654 [==============================] - 0s 369us/sample - loss: 1.8672 - mape: 94.0567\n",
      "Epoch 17/100\n",
      "654/654 [==============================] - 0s 378us/sample - loss: 1.7676 - mape: 91.6682\n",
      "Epoch 18/100\n",
      "654/654 [==============================] - 0s 373us/sample - loss: 1.7384 - mape: 96.2361\n",
      "Epoch 19/100\n",
      "654/654 [==============================] - 0s 371us/sample - loss: 1.8961 - mape: 95.7019\n",
      "Epoch 20/100\n",
      "654/654 [==============================] - 0s 371us/sample - loss: 1.9609 - mape: 95.5943\n",
      "Epoch 21/100\n",
      "654/654 [==============================] - 0s 355us/sample - loss: 1.8462 - mape: 92.4890\n",
      "Epoch 22/100\n",
      "654/654 [==============================] - 0s 363us/sample - loss: 1.8946 - mape: 90.7782\n",
      "Epoch 23/100\n",
      "654/654 [==============================] - 0s 367us/sample - loss: 1.7737 - mape: 96.2718\n",
      "Epoch 24/100\n",
      "654/654 [==============================] - 0s 397us/sample - loss: 1.8622 - mape: 96.2386\n",
      "Epoch 25/100\n",
      "654/654 [==============================] - 0s 382us/sample - loss: 1.8234 - mape: 94.9789\n",
      "Epoch 26/100\n",
      "654/654 [==============================] - 0s 385us/sample - loss: 1.7025 - mape: 97.1608\n",
      "Epoch 27/100\n",
      "654/654 [==============================] - 0s 391us/sample - loss: 1.8738 - mape: 105.3875\n",
      "Epoch 28/100\n",
      "654/654 [==============================] - 0s 396us/sample - loss: 1.8559 - mape: 100.7561\n",
      "Epoch 29/100\n",
      "654/654 [==============================] - 0s 387us/sample - loss: 1.6161 - mape: 97.3324\n",
      "Epoch 30/100\n",
      "654/654 [==============================] - 0s 374us/sample - loss: 1.7072 - mape: 92.3854\n",
      "Epoch 31/100\n",
      "654/654 [==============================] - 0s 368us/sample - loss: 1.8091 - mape: 86.8104\n",
      "Epoch 32/100\n",
      "654/654 [==============================] - 0s 366us/sample - loss: 1.6478 - mape: 89.2666\n",
      "Epoch 33/100\n",
      "654/654 [==============================] - 0s 360us/sample - loss: 1.8869 - mape: 85.3366\n",
      "Epoch 34/100\n",
      "654/654 [==============================] - 0s 357us/sample - loss: 1.5980 - mape: 88.3779\n",
      "Epoch 35/100\n",
      "654/654 [==============================] - 0s 363us/sample - loss: 1.6632 - mape: 87.0110\n",
      "Epoch 36/100\n",
      "654/654 [==============================] - 0s 385us/sample - loss: 1.6280 - mape: 86.1628\n",
      "Epoch 37/100\n",
      "654/654 [==============================] - 0s 394us/sample - loss: 1.7926 - mape: 85.1640\n",
      "Epoch 38/100\n",
      "654/654 [==============================] - 0s 393us/sample - loss: 1.6489 - mape: 86.7675\n",
      "Epoch 39/100\n",
      "654/654 [==============================] - 0s 391us/sample - loss: 1.6097 - mape: 89.2514\n",
      "Epoch 40/100\n",
      "654/654 [==============================] - 0s 369us/sample - loss: 1.6906 - mape: 92.8063\n",
      "Epoch 41/100\n",
      "654/654 [==============================] - 0s 369us/sample - loss: 1.7715 - mape: 94.6448\n",
      "Epoch 42/100\n",
      "654/654 [==============================] - 0s 367us/sample - loss: 1.6693 - mape: 91.3366\n",
      "Epoch 43/100\n",
      "654/654 [==============================] - 0s 359us/sample - loss: 1.6240 - mape: 88.9128\n",
      "Epoch 44/100\n",
      "654/654 [==============================] - 0s 362us/sample - loss: 1.6990 - mape: 90.5679\n",
      "Epoch 45/100\n",
      "654/654 [==============================] - 0s 390us/sample - loss: 1.5215 - mape: 92.7428\n",
      "Epoch 46/100\n",
      "654/654 [==============================] - 0s 385us/sample - loss: 1.5392 - mape: 95.6497\n",
      "Epoch 47/100\n",
      "654/654 [==============================] - 0s 401us/sample - loss: 1.5792 - mape: 94.2453\n",
      "Epoch 48/100\n",
      "654/654 [==============================] - 0s 388us/sample - loss: 1.6943 - mape: 93.7719\n",
      "Epoch 49/100\n",
      "654/654 [==============================] - 0s 386us/sample - loss: 1.4639 - mape: 99.5335\n",
      "Epoch 50/100\n",
      "654/654 [==============================] - 0s 362us/sample - loss: 1.5756 - mape: 98.2221\n",
      "Epoch 51/100\n",
      "654/654 [==============================] - 0s 371us/sample - loss: 1.6415 - mape: 97.3087\n",
      "Epoch 52/100\n",
      "654/654 [==============================] - 0s 363us/sample - loss: 1.6493 - mape: 95.7407\n",
      "Epoch 53/100\n",
      "654/654 [==============================] - 0s 362us/sample - loss: 1.4984 - mape: 92.9112\n",
      "Epoch 54/100\n",
      "654/654 [==============================] - 0s 369us/sample - loss: 1.4941 - mape: 93.4907\n",
      "Epoch 55/100\n",
      "654/654 [==============================] - 0s 363us/sample - loss: 1.4960 - mape: 97.9637\n",
      "Epoch 56/100\n",
      "654/654 [==============================] - 0s 381us/sample - loss: 1.7917 - mape: 104.5737\n",
      "Epoch 57/100\n",
      "654/654 [==============================] - 0s 355us/sample - loss: 1.6375 - mape: 105.2195\n",
      "Epoch 58/100\n",
      "654/654 [==============================] - 0s 380us/sample - loss: 1.6747 - mape: 103.0267\n",
      "Epoch 59/100\n",
      "654/654 [==============================] - 0s 391us/sample - loss: 1.4711 - mape: 104.1586\n",
      "Epoch 60/100\n",
      "654/654 [==============================] - 0s 407us/sample - loss: 1.6291 - mape: 103.0416\n",
      "Epoch 61/100\n",
      "654/654 [==============================] - 0s 386us/sample - loss: 1.5884 - mape: 101.8616\n",
      "Epoch 62/100\n",
      "654/654 [==============================] - 0s 396us/sample - loss: 1.7044 - mape: 101.0697\n",
      "Epoch 63/100\n",
      "654/654 [==============================] - ETA: 0s - loss: 1.7357 - mape: 102.73 - 0s 394us/sample - loss: 1.6372 - mape: 102.0123\n",
      "Epoch 64/100\n",
      "654/654 [==============================] - 0s 375us/sample - loss: 1.6592 - mape: 97.1784\n",
      "Epoch 65/100\n",
      "654/654 [==============================] - 0s 393us/sample - loss: 1.5219 - mape: 98.3055\n",
      "Epoch 66/100\n",
      "654/654 [==============================] - 0s 393us/sample - loss: 1.4881 - mape: 100.8150\n",
      "Epoch 67/100\n",
      "654/654 [==============================] - 0s 388us/sample - loss: 1.5497 - mape: 98.8022\n",
      "Epoch 68/100\n",
      "654/654 [==============================] - 0s 402us/sample - loss: 1.5571 - mape: 97.3082\n",
      "Epoch 69/100\n",
      "654/654 [==============================] - 0s 395us/sample - loss: 1.6047 - mape: 102.7614\n",
      "Epoch 70/100\n",
      "654/654 [==============================] - 0s 386us/sample - loss: 1.6734 - mape: 103.4771\n",
      "Epoch 71/100\n",
      "654/654 [==============================] - 0s 388us/sample - loss: 1.5862 - mape: 103.6244\n",
      "Epoch 72/100\n",
      "654/654 [==============================] - 0s 376us/sample - loss: 1.5783 - mape: 102.9925 - loss: 1.2082 - mape: \n",
      "Epoch 73/100\n",
      "654/654 [==============================] - 0s 366us/sample - loss: 1.5347 - mape: 101.6105\n",
      "Epoch 74/100\n",
      "654/654 [==============================] - 0s 374us/sample - loss: 1.4378 - mape: 102.3506\n",
      "Epoch 75/100\n",
      "654/654 [==============================] - 0s 371us/sample - loss: 1.4412 - mape: 103.3427\n",
      "Epoch 76/100\n",
      "654/654 [==============================] - 0s 379us/sample - loss: 1.6547 - mape: 101.6959\n",
      "Epoch 77/100\n",
      "654/654 [==============================] - 0s 381us/sample - loss: 1.5449 - mape: 100.8948\n",
      "Epoch 78/100\n",
      "654/654 [==============================] - 0s 378us/sample - loss: 1.5495 - mape: 101.0129\n",
      "Epoch 79/100\n",
      "654/654 [==============================] - 0s 364us/sample - loss: 1.4482 - mape: 103.1943\n",
      "Epoch 80/100\n",
      "654/654 [==============================] - 0s 375us/sample - loss: 1.7306 - mape: 102.3627\n",
      "Epoch 81/100\n",
      "654/654 [==============================] - 0s 363us/sample - loss: 1.5208 - mape: 99.3309\n",
      "Epoch 82/100\n",
      "654/654 [==============================] - 0s 366us/sample - loss: 1.4580 - mape: 99.0422\n",
      "Epoch 83/100\n",
      "654/654 [==============================] - 0s 347us/sample - loss: 1.4361 - mape: 99.4207\n",
      "Epoch 84/100\n",
      "654/654 [==============================] - 0s 372us/sample - loss: 1.6017 - mape: 101.6005\n",
      "Epoch 85/100\n",
      "654/654 [==============================] - 0s 371us/sample - loss: 1.5210 - mape: 101.3205\n",
      "Epoch 86/100\n",
      "654/654 [==============================] - 0s 377us/sample - loss: 1.4961 - mape: 100.3648\n",
      "Epoch 87/100\n",
      "654/654 [==============================] - 0s 371us/sample - loss: 1.4082 - mape: 98.5613\n",
      "Epoch 88/100\n",
      "654/654 [==============================] - 0s 371us/sample - loss: 1.5054 - mape: 99.1694\n",
      "Epoch 89/100\n",
      "654/654 [==============================] - 0s 366us/sample - loss: 1.5739 - mape: 99.3342\n",
      "Epoch 90/100\n",
      "654/654 [==============================] - 0s 366us/sample - loss: 1.4382 - mape: 98.0884\n",
      "Epoch 91/100\n",
      "654/654 [==============================] - 0s 379us/sample - loss: 1.5455 - mape: 97.1986\n",
      "Epoch 92/100\n",
      "654/654 [==============================] - 0s 363us/sample - loss: 1.5165 - mape: 95.2429\n",
      "Epoch 93/100\n",
      "654/654 [==============================] - 0s 365us/sample - loss: 1.4331 - mape: 96.8739\n",
      "Epoch 94/100\n",
      "654/654 [==============================] - 0s 379us/sample - loss: 1.4603 - mape: 96.8071\n",
      "Epoch 95/100\n",
      "654/654 [==============================] - 0s 370us/sample - loss: 1.4374 - mape: 100.7118\n",
      "Epoch 96/100\n",
      "654/654 [==============================] - 0s 368us/sample - loss: 1.4345 - mape: 105.2867\n",
      "Epoch 97/100\n",
      "654/654 [==============================] - 0s 385us/sample - loss: 1.6516 - mape: 107.6022\n",
      "Epoch 98/100\n",
      "654/654 [==============================] - 0s 374us/sample - loss: 1.3746 - mape: 104.2236\n",
      "Epoch 99/100\n",
      "654/654 [==============================] - 0s 370us/sample - loss: 1.5224 - mape: 103.5968\n",
      "Epoch 100/100\n",
      "654/654 [==============================] - 0s 367us/sample - loss: 1.4331 - mape: 104.0492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdfb43d4d50>"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "particular-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "notify(\"Model\", \"Model training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "minus-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('saved/weights_m2_UAL.h5', overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-building",
   "metadata": {},
   "source": [
    "#### Output and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "worth-nation",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.644340474306626, 9.025341]"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X2 = full_data[indices[m:m+0],:-1,:]\n",
    "# Y2 = full_data[indices[m:m+0],-1:,:]\n",
    "# Y2 = Y2.reshape(Y2.shape[0], Y2.shape[2])\n",
    "model.evaluate(X, Y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "requested-diving",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X3 = full_data[indices[1000],:-1,:]\n",
    "# Y3 = full_data[indices[1000],-1:,:]\n",
    "# print(sc.inverse_transform(model.predict(X3.reshape(1, *X3.shape))))\n",
    "# print(sc.inverse_transform(X3))\n",
    "# print(sc.inverse_transform(Y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "mounted-snapshot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdfb68c0f90>]"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(access_ticker(df_main, 'AAPL')['Market Cap'][0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-accent",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_backtest = 1500\n",
    "n_predictions = 500\n",
    "\n",
    "sample_stock = 'AAPL'\n",
    "sample_data = dataset[sample_stock].copy()\n",
    "rolling_input = sample_data[(-n_forward-n_trailing+1)-n_backtest:-n_backtest] # selects all timesteps necessary for n_backtest predictions to run, and then enough to continue in a cycle (i.e., n_trailing+n_forward-1)\n",
    "sample_output = []\n",
    "for i in range(n_predictions):\n",
    "    sample_input = np.array(rolling_input[:n_trailing]) # selects the first n_trailing timesteps to make the next prediction\n",
    "    sample_input = sample_input.reshape(1, *sample_input.shape) # reshape into model input format\n",
    "    sample_output.append(model.predict(sample_input).ravel())\n",
    "    rolling_input[:-1] = rolling_input[1:] # shift one to the left\n",
    "    rolling_input[-1:] = sample_output[i]\n",
    "#     print(sample_input[0,0], \", \", sample_output[i])\n",
    "sample_output = np.array(sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sample_output[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 0\n",
    "output = np.append((dataset[sample_stock][:-n_backtest-1])[:,val], sample_output[:,val])\n",
    "sample_Y = (dataset[sample_stock])[:,val]\n",
    "\n",
    "max_range_true = len(dataset[sample_stock])-n_backtest-1\n",
    "max_range_pred = max_range_true+n_predictions\n",
    "\n",
    "plt.plot(sample_Y)\n",
    "plt.plot(np.arange(max_range_true), output[np.arange(max_range_true)]) # plot all actual values\n",
    "plt.plot(np.arange(max_range_true-1, max_range_pred), output[np.arange(max_range_true-1, max_range_pred)]) # plot all predicted values in different color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = np.array(generate_sequences(dataset[sample_stock]))[:,:-1]\n",
    "sample_output = model.predict(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 0\n",
    "output = np.append((dataset[sample_stock][:n_trailing+n_forward])[:,val], sample_output[:,val])\n",
    "sample_Y = (dataset[sample_stock])[:,val]\n",
    "\n",
    "plt.plot(sample_Y)\n",
    "plt.plot(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "notify(\"Model\", \"Model prediction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(access_ticker(df_prices, 'AAPL')['Market Cap'])\n",
    "plt.plot(dataset[sample_stock][:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
