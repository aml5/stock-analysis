V1.0-V3.0

03/20/21: Beginning of project, primarily addressed loading text and began building model, though not very successful results yet. First model yielded mediocre results from an approximate view, but could not predict, so attempted model 2, with a for loop over single LSTM and dense layer for each time step, but model compilation unsuccessful (fixing bugs also took a long time, particularly be careful of output dimensions). So I developed model 3, which used same LSTM structure as model 1, but more layers (also reorganized data generation during model 2 development) so a pretty clean and slightly better results than previous models. Also attempted MinMaxScaler but was unsuccessful. Even though model 3 had decent results, it could not predict due to the nature of its architecture (a many-to-many model).

V4.0-V4.1

03/21/21: Developed model 4. Model 4 uses a different architecture, using T_x timesteps to project the value n_lag days in the future. Started off with a simple model and developed deeper model. Same as before, started off disorganized with the dataset generation because it is temporary.

03/22/21: Included pandas library for data import. Significant difficulty at first upscaling from quarterly to daily, attempting a pivot table, but failed to assign values properly (always returned NaN), same with a for loop over groups. Lambda with groups yielded desired results.

03/23/21: Success with merging two datasets by Ticker, Date and exporting to numpy. Further success with implementing YoY revenue growth and cleaning data to remove any incomplete data. Began building model, but returned NaN loss value.

V5.0-V5.1

03/24/21: Simplification and cleaning of code. Transformed data using MinMaxScaler. Model now able to run successfully. Need to fix naming. Further simplification of code into methods. Improved model with additional layers, improved scaling, and created rudimentary prediction graph. Pivot table changed column order to alphabetical so reordered in order to be compatible with MinMaxScaler.

03/25/21: Implemented mean squared error loss function with custom weighting. Weighting: weights_m1 [100,1,1,1,10]. Debugged predict ability and potential model issues including MAPE loss, using logs. Tested on Tx=1, n_forward=1. Some of the variance in the results came from random initialization. MAPE seems to underperform MSE in most cases, especially with a log preprocess. Recompiling/reinitializing model is critical. Implemented prediction in procedural format. Training error in high digits of 1e-6. Experimenting with different T_x and n_forward values.

03/26/21: Tx360 n_f360 epochs15 results are not strong because prediction cost does not have a strong effect on some of the output units, and those units are necessary for strong predictions (maybe not actually, since it is only looking at true values when n_predictions < n_forward). May consider cutting from 5 inputs to 2 inputs to see if improves situation. UAL Tx360 n_f360 epochs15 weight only on 1st output unit -> decent output, but will need to look at other stocks. UAL Tx360 n_f360 epochs15 weight uniform on all output units -> worse output results. AAPL Tx360 n_f360 epochs15 loss weight uniform -> flat prediction for the most part. May need to double check prediction process. Same as previous but 2x loss weight on first unit -> better prediction. Perhaps a bit of overfitting, but that will improve with expanding to entire dataset. Implemented coloring to prediction graph for better visualization. Attempted related model (v5.1.1) with dense neural network to take one input and project forward many years, decent, but not super precise results. Prior to v5.1.1, tried LSTM with Tx1, and it seems LSTM performs worse when there are few timesteps. Cleaned prediction code into simplified methods. Cleaned code for inverse scaling for plotting, debugged custom loss functions. All Tx5 n_f360 epochs5 yielded pretty strong results. Lessons learned: LSTMs perform poorly with few timesteps, MinMaxScale then log then MinMaxScale works pretty well, weighted 2x for loss on first unit seems to provide strong results, mean squared error works.

V5.2

03/27/21: Tx200/7 n_f360/7 epochs8 2x loss weight on unit 1 results in some kind of up and down sequence with little predictive power and pretty bad results. Tx5 n_f360 epochs8 2x loss weight on unit 1 pretty good results. Attempting to fix the issue of MAPE loss metric being extremely large. I think part of the reason was that the second MinMaxScaler had a low end of 1e-16, so the loss would not be able to appropriately account for many of those because it would just be so small that even a tiny change of 1e-10 or something like that would lead to a massive MAPE increase. Two possibilities are to have a range that starts at a little above 0, or to use a different system of standardization. The latter addresses another issue, namely that the MinMaxScaler has predefined min and max, and if there are outliers, it can significantly impact the loss calculation. Tx5 n_f360 epochs8 with standard scaler decent results. Will try feature normalization through divide by mean and L2 norm. Moving away from MinMax. Lambda train on divide by mean and divide by frobenius (L2) norm yielded okay, but worse results than feature normalization with StandardScaler, default Tx5 n_f360 epochs8 for faster training. Tx5 n_f360 epochs8 StandardScaler, 3x loss weight on 1st unit, pretty good but not the best results, weights saved in m3 h5 file. Tx200 n_f360 epochs12 1M training is the best performance model to date, trained on lambda model v5.1. Improved prediction method by allowing it to extend beyond the last known date to as far as n_forward timesteps beyond dataset, using the most recent timesteps, rather than being restricted to just predicting in the range of known values. Attempted model v5.2, which has compatible weights with v5.1, but includes regularization and further dropout. Running the model has been for the most part unsuccessful. weights_l3_200_360.h5 is still the best performer (most previous weights all similarly use v5.1). Will run Tx200 n_f360 epochs12 1M training with model v5.2 (reg 0.01, drop 0.3) to see if it yields better results. So far, regularization and dropout has led to worse results in training and running some test/validation does not yield significantly better results, maybe even worse results. Tx200 n_f360 epochs12 1M training on model v5.2 saved weights in weights_l5 h5 file. Poor results. Weights l3 and weights l4 remain the best for their respective n_trailing timesteps as input.


Project conclusions:
- Feature scaling is highly important when it comes to the loss function. Standard scaling (mean normalization) is a strong candidate, I did not try standard scaling with logging, but it may work even better for loss. MinMaxScaler only works if the minimum and maximum for each feature is known or can be controlled.
- LSTMs perform worse when there are few (close to 1) timesteps.
- Data preprocessing takes up the vast majority of the time. Model development itself can take as short as 15 minutes. Incomplete or inaccurate data can seriously affect performance.
- Determine the goals, inputs, and outputs of the model and design before implementing. An outline may be useful.
- Mean absolute percentage error is not necessarily a good loss function, especially when working with a range close to 0. Mean squared error, the default, typically fits well.
- GPU runs the model very significantly faster (perhaps 100x) than CPU on larger inputs.
- Keep track of commonly used functions and implement them as methods for easy access.
- Looking at previous examples online can be very useful for model architecture, algorithms, and processing methods.

Done:
- Filter only mid-cap and above stocks
- Implement effective prediction and visualization
- Implement one forward prediction
- Option for weekly instead of daily

Still left to do: